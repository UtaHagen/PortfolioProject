{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7defea",
   "metadata": {
    "papermill": {
     "duration": 0.009799,
     "end_time": "2024-09-15T18:03:48.662184",
     "exception": false,
     "start_time": "2024-09-15T18:03:48.652385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Unsupervised Learning Trading Strategy\n",
    "\n",
    "* Download/Load SP500 stocks prices data.\n",
    "* Calculate different features and indicators on each stock.\n",
    "* Aggregate on monthly level and filter top 150 most liquid stocks.\n",
    "* Calculate Monthly Returns for different time-horizons.\n",
    "* Download Fama-French Factors and Calculate Rolling Factor Betas.\n",
    "* For each month fit a K-Means Clustering Algorithm to group similar assets based on their features.\n",
    "* For each month select assets based on the cluster and form a portfolio based on Efficient Frontier max sharpe ratio optimization.\n",
    "* Visualize Portfolio returns and compare to SP500 returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf4331",
   "metadata": {
    "papermill": {
     "duration": 0.005896,
     "end_time": "2024-09-15T18:03:48.675152",
     "exception": false,
     "start_time": "2024-09-15T18:03:48.669256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# All Packages Needed:\n",
    "* pandas, numpy, matplotlib, statsmodels, pandas_datareader, datetime, yfinance, sklearn, PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeddf97",
   "metadata": {
    "papermill": {
     "duration": 0.005763,
     "end_time": "2024-09-15T18:03:48.687075",
     "exception": false,
     "start_time": "2024-09-15T18:03:48.681312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Download/Load SP500 stocks prices data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c27326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:03:48.729457Z",
     "iopub.status.busy": "2024-09-15T18:03:48.729284Z",
     "iopub.status.idle": "2024-09-15T18:03:50.485365Z",
     "shell.execute_reply": "2024-09-15T18:03:50.484972Z"
    },
    "papermill": {
     "duration": 1.762594,
     "end_time": "2024-09-15T18:03:50.486596",
     "exception": false,
     "start_time": "2024-09-15T18:03:48.724002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas_ta\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1d8f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:03:50.497297Z",
     "iopub.status.busy": "2024-09-15T18:03:50.497011Z",
     "iopub.status.idle": "2024-09-15T18:03:57.311497Z",
     "shell.execute_reply": "2024-09-15T18:03:57.310660Z"
    },
    "papermill": {
     "duration": 6.303391,
     "end_time": "2024-09-15T18:03:56.794851",
     "exception": false,
     "start_time": "2024-09-15T18:03:50.491460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[                       0%                       ]  2 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[                       1%                       ]  3 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[                       1%                       ]  4 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[                       1%                       ]  5 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[                       1%                       ]  6 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[                       1%                       ]  7 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      2%                       ]  8 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      2%                       ]  9 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      2%                       ]  10 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      2%                       ]  11 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      2%                       ]  12 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      3%                       ]  13 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      3%                       ]  14 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      3%                       ]  15 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      3%                       ]  16 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*                      3%                       ]  17 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     4%                       ]  18 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     4%                       ]  19 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     4%                       ]  20 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     4%                       ]  21 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     4%                       ]  22 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     5%                       ]  23 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     5%                       ]  24 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     5%                       ]  25 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     5%                       ]  26 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**                     5%                       ]  27 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    6%                       ]  28 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    6%                       ]  29 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    6%                       ]  30 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    6%                       ]  31 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    6%                       ]  31 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    7%                       ]  33 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    7%                       ]  34 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    7%                       ]  35 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    7%                       ]  36 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    7%                       ]  37 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***                    7%                       ]  37 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   8%                       ]  39 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   8%                       ]  40 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   8%                       ]  41 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   8%                       ]  42 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   9%                       ]  43 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   9%                       ]  44 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   9%                       ]  45 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   9%                       ]  46 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[****                   9%                       ]  47 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 10%                       ]  48 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 10%                       ]  49 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 10%                       ]  50 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 10%                       ]  51 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 10%                       ]  52 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 11%                       ]  53 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 11%                       ]  54 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 11%                       ]  55 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 11%                       ]  56 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*****                 11%                       ]  57 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[******                12%                       ]  58 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[******                12%                       ]  59 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[******                12%                       ]  60 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[******                12%                       ]  61 of 503 completed\r",
      "[******                12%                       ]  61 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[******                13%                       ]  63 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[******                13%                       ]  64 of 503 completed\r",
      "[******                13%                       ]  64 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[******                13%                       ]  66 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[******                13%                       ]  67 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               14%                       ]  68 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               14%                       ]  69 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               14%                       ]  70 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               14%                       ]  71 of 503 completed\r",
      "[*******               14%                       ]  71 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               15%                       ]  73 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               15%                       ]  74 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               15%                       ]  75 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               15%                       ]  76 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*******               15%                       ]  77 of 503 completed\r",
      "[*******               15%                       ]  77 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              16%                       ]  79 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              16%                       ]  80 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              16%                       ]  81 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              16%                       ]  82 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              17%                       ]  83 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              17%                       ]  84 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              17%                       ]  85 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              17%                       ]  86 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              17%                       ]  86 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[********              17%                       ]  88 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             18%                       ]  89 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             18%                       ]  90 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             18%                       ]  91 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             18%                       ]  92 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             18%                       ]  93 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             19%                       ]  94 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             19%                       ]  95 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             19%                       ]  96 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             19%                       ]  97 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********             19%                       ]  98 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            20%                       ]  99 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            20%                       ]  100 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            20%                       ]  100 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            20%                       ]  102 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            20%                       ]  103 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            21%                       ]  104 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            21%                       ]  105 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            21%                       ]  106 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            21%                       ]  107 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[**********            21%                       ]  108 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***********           22%                       ]  109 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***********           22%                       ]  109 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***********           22%                       ]  111 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***********           22%                       ]  112 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***********           22%                       ]  113 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***********           23%                       ]  114 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[***********           23%                       ]  115 of 503 completed"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m end_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-06-30\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m start_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(end_date)\u001b[38;5;241m-\u001b[39mpd\u001b[38;5;241m.\u001b[39mDateOffset(\u001b[38;5;241m365\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43myf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbols_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstack()\n\u001b[1;32m     19\u001b[0m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/envstock/lib/python3.11/site-packages/yfinance/utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[0;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/envstock/lib/python3.11/site-packages/yfinance/multi.py:152\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session)\u001b[0m\n\u001b[1;32m    145\u001b[0m         _download_one_threaded(ticker, period\u001b[38;5;241m=\u001b[39mperiod, interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[1;32m    146\u001b[0m                                start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, prepost\u001b[38;5;241m=\u001b[39mprepost,\n\u001b[1;32m    147\u001b[0m                                actions\u001b[38;5;241m=\u001b[39mactions, auto_adjust\u001b[38;5;241m=\u001b[39mauto_adjust,\n\u001b[1;32m    148\u001b[0m                                back_adjust\u001b[38;5;241m=\u001b[39mback_adjust, repair\u001b[38;5;241m=\u001b[39mrepair, keepna\u001b[38;5;241m=\u001b[39mkeepna,\n\u001b[1;32m    149\u001b[0m                                progress\u001b[38;5;241m=\u001b[39m(progress \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[1;32m    150\u001b[0m                                rounding\u001b[38;5;241m=\u001b[39mrounding, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared\u001b[38;5;241m.\u001b[39m_DFS) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[0;32m--> 152\u001b[0m         _time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "\n",
    "sp500['Symbol'] = sp500['Symbol'].str.replace('.', '-')\n",
    "\n",
    "symbols_list = sp500['Symbol'].unique().tolist()\n",
    "\n",
    "end_date = '2024-06-30'\n",
    "\n",
    "start_date = pd.to_datetime(end_date)-pd.DateOffset(365*8)\n",
    "\n",
    "df = yf.download(tickers=symbols_list,\n",
    "                 start=start_date,\n",
    "                 end=end_date).stack()\n",
    "\n",
    "df.index.names = ['date', 'ticker']\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbf22c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df\n",
    "df2 = df.copy()\n",
    "df3 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7842ea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num, colu = df.loc[pd.IndexSlice['2024-06-06',:],:].shape\n",
    "num\n",
    "ticker=df.loc['2024-06-06',:].index\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba1218",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a380a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = ['Year', 'Month', 'Week', 'Day of the month', 'log_return', 'sma_50', 'sma_200', 'rsi']\n",
    "targets = ['close', 'adj close', 'volume', 'high', 'low', 'open']\n",
    "\n",
    "i = 0\n",
    "for i in range(0,num):\n",
    "\n",
    "    df_aapl = df1.loc[pd.IndexSlice[:, ticker[i]], :]\n",
    "    df_aapl=df_aapl.reset_index()\n",
    "    df_aapl['log_return'] = np.log(df_aapl['close'] / df_aapl['close'].shift(1))\n",
    "    df_aapl['sma_50'] = df_aapl['close'].rolling(window=50).mean()\n",
    "    df_aapl['sma_200'] = df_aapl['close'].rolling(window=200).mean()\n",
    "    df_aapl['rsi'] = 100 - (100 / (1 + (df_aapl['close'].diff().rolling(window=14).mean() / df_aapl['close'].diff().rolling(window=14).std())))\n",
    "\n",
    "    last_date = df_aapl['date'].max()\n",
    "    new_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=150)\n",
    "    new_data = {\n",
    "    'date': new_dates,\n",
    "    'ticker': ticker[i],\n",
    "    'adj close': 0,\n",
    "    'close': 0,\n",
    "    'high': 0,\n",
    "    'low': 0,\n",
    "    'open': 0,\n",
    "    'volume': 0,\n",
    "    'log_return':0,\n",
    "    'sma_200':0,\n",
    "    'sma_50':0,\n",
    "    'rsi':0\n",
    "    }\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    df_aapl = pd.concat([df_aapl, new_df], ignore_index=True)\n",
    "\n",
    "    df_aapl['Month'] = df_aapl['date'].dt.month\n",
    "    df_aapl['Year'] = df_aapl['date'].dt.year\n",
    "    df_aapl['Week'] = df_aapl['date'].dt.isocalendar().week\n",
    "    df_aapl['Day of the month'] = df_aapl['date'].dt.day\n",
    "    \n",
    "    df_aapl.set_index('date', inplace=True)\n",
    "    X = df_aapl[features]\n",
    "    y = df_aapl[targets]\n",
    "    \n",
    "    train_size = len(df_aapl) - 150\n",
    "    X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "    y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "    # Train the XGBoost model for each target\n",
    "    models = {}\n",
    "    for target in targets:\n",
    "        model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "        model.fit(X_train, y_train[target])\n",
    "        models[target] = model\n",
    "\n",
    "    # Make predictions for each target\n",
    "    predictions = {}\n",
    "    for target in targets:\n",
    "        predictions[target] = models[target].predict(X_test)\n",
    "\n",
    "    # Combine predictions into a DataFrame\n",
    "    predicted_df = pd.DataFrame(predictions, index=X_test.index)\n",
    "    predicted_df['ticker']=ticker[i]\n",
    "#     predicted_df = predicted_df.reset_index()\n",
    "#     predicted_df.set_index('ticker', append=True, inplace=True)\n",
    "    predicted_df.set_index(['ticker', predicted_df.index], inplace=True)\n",
    "    predicted_df.index.names = ['ticker', 'date']\n",
    "    predicted_df = predicted_df.reorder_levels(['date', 'ticker'])\n",
    "  \n",
    "    df = pd.concat([df2, predicted_df], ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25073c54",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df\n",
    "df_final1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab099e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19046388",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_final = df_final.sortlevel()\n",
    "df_final = df_final.groupby(level=[0,1]).sum()\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649b20d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55746c31",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Calculate features and technical indicators for each stock.\n",
    "\n",
    "* Garman-Klass Volatility\n",
    "* RSI\n",
    "* Bollinger Bands\n",
    "* ATR\n",
    "* MACD\n",
    "* Dollar Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94feae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\\begin{equation}\n",
    "\\text{Garman-Klass Volatility} = \\frac{(\\ln(\\text{High}) - \\ln(\\text{Low}))^2}{2} - (2\\ln(2) - 1)(\\ln(\\text{Adj Close}) - \\ln(\\text{Open}))^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fd2a6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['garman_klass_vol'] = ((np.log(df['high'])-np.log(df['low']))**2)/2-(2*np.log(2)-1)*((np.log(df['adj close'])-np.log(df['open']))**2)\n",
    "\n",
    "df['rsi'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.rsi(close=x, length=20))\n",
    "\n",
    "df['bb_low'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,0])\n",
    "                                                          \n",
    "df['bb_mid'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,1])\n",
    "                                                          \n",
    "df['bb_high'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,2])\n",
    "\n",
    "def compute_atr(stock_data):\n",
    "    atr = pandas_ta.atr(high=stock_data['high'],\n",
    "                        low=stock_data['low'],\n",
    "                        close=stock_data['close'],\n",
    "                        length=14)\n",
    "    return atr.sub(atr.mean()).div(atr.std())\n",
    "\n",
    "df['atr'] = df.groupby(level=1, group_keys=False).apply(compute_atr)\n",
    "\n",
    "def compute_macd(close):\n",
    "    macd = pandas_ta.macd(close=close, length=20).iloc[:,0]\n",
    "    return macd.sub(macd.mean()).div(macd.std())\n",
    "\n",
    "df['macd'] = df.groupby(level=1, group_keys=False)['adj close'].apply(compute_macd)\n",
    "\n",
    "df['dollar_volume'] = (df['adj close']*df['volume'])/1e6\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e7ef78",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_feature = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c735696b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Aggregate to monthly level and filter top 150 most liquid stocks for each month.\n",
    "\n",
    "* To reduce training time and experiment with features and strategies, we convert the business-daily data to month-end frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec67c59",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_cols = [c for c in df.columns.unique(0) if c not in ['dollar_volume', 'volume', 'open',\n",
    "                                                          'high', 'low', 'close']]\n",
    "\n",
    "data = (pd.concat([df.unstack('ticker')['dollar_volume'].resample('M').mean().stack('ticker').to_frame('dollar_volume'),\n",
    "                   df.unstack()[last_cols].resample('M').last().stack('ticker')],\n",
    "                  axis=1)).dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a39907",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_copy = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632ffc7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Calculate 5-year rolling average of dollar volume for each stocks before filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5208030",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['dollar_volume'] = (data.loc[:, 'dollar_volume'].unstack('ticker').rolling(5*12, min_periods=12).mean().stack())\n",
    "\n",
    "data['dollar_vol_rank'] = (data.groupby('date')['dollar_volume'].rank(ascending=False))\n",
    "\n",
    "data = data[data['dollar_vol_rank']<150].drop(['dollar_volume', 'dollar_vol_rank'], axis=1)\n",
    "\n",
    "data\n",
    "\n",
    "data_copy2 = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e13a3b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Calculate Monthly Returns for different time horizons as features.\n",
    "\n",
    "* To capture time series dynamics that reflect, for example, momentum patterns, we compute historical returns using the method .pct_change(lag), that is, returns over various monthly periods as identified by lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8d55d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_returns(df):\n",
    "\n",
    "    outlier_cutoff = 0.005\n",
    "\n",
    "    lags = [1, 2, 3, 6, 9, 12]\n",
    "\n",
    "    for lag in lags:\n",
    "\n",
    "        df[f'return_{lag}m'] = (df['adj close']\n",
    "                              .pct_change(lag)\n",
    "                              .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                                     upper=x.quantile(1-outlier_cutoff)))\n",
    "                              .add(1)\n",
    "                              .pow(1/lag)\n",
    "                              .sub(1))\n",
    "    return df\n",
    "    \n",
    "    \n",
    "data = data.groupby(level=1, group_keys=False).apply(calculate_returns).dropna()\n",
    "\n",
    "data\n",
    "data_final = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df434b55",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Download Fama-French Factors and Calculate Rolling Factor Betas.\n",
    "\n",
    "* We will introduce the Fama—French data to estimate the exposure of assets to common risk factors using linear regression.\n",
    "\n",
    "* The five Fama—French factors, namely market risk, size, value, operating profitability, and investment have been shown empirically to explain asset returns and are commonly used to assess the risk/return profile of portfolios. Hence, it is natural to include past factor exposures as financial features in models.\n",
    "\n",
    "* We can access the historical factor returns using the pandas-datareader and estimate historical exposures using the RollingOLS rolling linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a7ab7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "factor_data = web.DataReader('F-F_Research_Data_5_Factors_2x3',\n",
    "                               'famafrench',\n",
    "                               start='2010')[0].drop('RF', axis=1)\n",
    "\n",
    "factor_data.index = factor_data.index.to_timestamp()\n",
    "\n",
    "factor_data = factor_data.resample('M').last().div(100)\n",
    "\n",
    "factor_data.index.name = 'date'\n",
    "\n",
    "data = data.reset_index()\n",
    "if data['date'].dt.tz is not None:\n",
    "    data['date'] = data['date'].dt.tz_localize(None)\n",
    "data = data.set_index(['date', 'ticker'])\n",
    "\n",
    "factor_data = factor_data.join(data['return_1m']).sort_index()\n",
    "\n",
    "factor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840bf3b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Filter out stocks with less than 10 months of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586d806",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "observations = factor_data.groupby(level=1).size()\n",
    "\n",
    "valid_stocks = observations[observations >= 10]\n",
    "\n",
    "factor_data = factor_data[factor_data.index.get_level_values('ticker').isin(valid_stocks.index)]\n",
    "\n",
    "factor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0107433",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Calculate Rolling Factor Betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364bbad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "betas = (factor_data.groupby(level=1,\n",
    "                            group_keys=False)\n",
    "         .apply(lambda x: RollingOLS(endog=x['return_1m'], \n",
    "                                     exog=sm.add_constant(x.drop('return_1m', axis=1)),\n",
    "                                     window=min(24, x.shape[0]),\n",
    "                                     min_nobs=len(x.columns)+1)\n",
    "         .fit(params_only=True)\n",
    "         .params\n",
    "         .drop('const', axis=1)))\n",
    "\n",
    "betas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491e61a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Join the rolling factors data to the main features dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169594b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "\n",
    "data = (data.join(betas.groupby('ticker').shift()))\n",
    "\n",
    "data.loc[:, factors] = data.groupby('ticker', group_keys=False)[factors].apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "data = data.drop('adj close', axis=1)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebd53b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eeb7f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### At this point we have to decide on what ML model and approach to use for predictions etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bbfb3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. For each month fit a K-Means Clustering Algorithm to group similar assets based on their features.\n",
    "\n",
    "### K-Means Clustering\n",
    "* You may want to initialize predefined centroids for each cluster based on your research.\n",
    "\n",
    "* For visualization purpose of this tutorial we will initially rely on the ‘k-means++’ initialization.\n",
    "\n",
    "* Then we will pre-define our centroids for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a94dc1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ca116",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_rsi_values = [30, 45, 55, 70]\n",
    "\n",
    "initial_centroids = np.zeros((len(target_rsi_values), 18))\n",
    "\n",
    "initial_centroids[:, 6] = target_rsi_values\n",
    "\n",
    "initial_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323ab80",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# data = data.drop('cluster', axis=1)\n",
    "\n",
    "def get_clusters(df):\n",
    "    df['cluster'] = KMeans(n_clusters=4,\n",
    "                           random_state=0,\n",
    "                           init=initial_centroids).fit(df).labels_\n",
    "    return df\n",
    "\n",
    "data = data.dropna().groupby('date', group_keys=False).apply(get_clusters)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66097e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_clusters(data):\n",
    "\n",
    "    cluster_0 = data[data['cluster']==0]\n",
    "    cluster_1 = data[data['cluster']==1]\n",
    "    cluster_2 = data[data['cluster']==2]\n",
    "    cluster_3 = data[data['cluster']==3]\n",
    "\n",
    "    plt.scatter(cluster_0.iloc[:,0] , cluster_0.iloc[:,6] , color = 'red', label='cluster 0')\n",
    "    plt.scatter(cluster_1.iloc[:,0] , cluster_1.iloc[:,6] , color = 'green', label='cluster 1')\n",
    "    plt.scatter(cluster_2.iloc[:,0] , cluster_2.iloc[:,6] , color = 'blue', label='cluster 2')\n",
    "    plt.scatter(cluster_3.iloc[:,0] , cluster_3.iloc[:,6] , color = 'black', label='cluster 3')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bd52f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "for i in data.index.get_level_values('date').unique().tolist():\n",
    "    \n",
    "    g = data.xs(i, level=0)\n",
    "    \n",
    "    plt.title(f'Date {i}')\n",
    "    \n",
    "    plot_clusters(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e52a4f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Apply pre-defined centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945fd54",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d28c49e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. For each month select assets based on the cluster and form a portfolio based on Efficient Frontier max sharpe ratio optimization\n",
    "\n",
    "* First we will filter only stocks corresponding to the cluster we choose based on our hypothesis.\n",
    "\n",
    "* Momentum is persistent and my idea would be that stocks clustered around RSI 70 centroid should continue to outperform in the following month - thus I would select stocks corresponding to cluster 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565941a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df = data[data['cluster']==3].copy()\n",
    "\n",
    "filtered_df = filtered_df.reset_index(level=1)\n",
    "\n",
    "filtered_df.index = filtered_df.index+pd.DateOffset(1)\n",
    "\n",
    "filtered_df = filtered_df.reset_index().set_index(['date', 'ticker'])\n",
    "\n",
    "dates = filtered_df.index.get_level_values('date').unique().tolist()\n",
    "\n",
    "fixed_dates = {}\n",
    "\n",
    "for d in dates:\n",
    "    \n",
    "    fixed_dates[d.strftime('%Y-%m-%d')] = filtered_df.xs(d, level=0).index.tolist()\n",
    "    \n",
    "fixed_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f9941",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define portfolio optimization function\n",
    "\n",
    "* We will define a function which optimizes portfolio weights using PyPortfolioOpt package and EfficientFrontier optimizer to maximize the sharpe ratio.\n",
    "\n",
    "* To optimize the weights of a given portfolio we would need to supply last 1 year prices to the function.\n",
    "\n",
    "* Apply signle stock weight bounds constraint for diversification (minimum half of equaly weight and maximum 10% of portfolio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931a4e7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49fcb5e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2888d07",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "def optimize_weights(prices, lower_bound=0):\n",
    "    \n",
    "    returns = expected_returns.mean_historical_return(prices=prices,\n",
    "                                                      frequency=252)\n",
    "    \n",
    "    cov = risk_models.sample_cov(prices=prices,\n",
    "                                 frequency=252)\n",
    "    \n",
    "    ef = EfficientFrontier(expected_returns=returns,\n",
    "                           cov_matrix=cov,\n",
    "                           weight_bounds=(lower_bound, .1),\n",
    "                           solver='SCS')\n",
    "    \n",
    "    weights = ef.max_sharpe()\n",
    "    \n",
    "    return ef.clean_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd59c17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Download Fresh Daily Prices Data only for short listed stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d737d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stocks = data.index.get_level_values('ticker').unique().tolist()\n",
    "\n",
    "# new_df = yf.download(tickers=stocks,\n",
    "#                      start=data.index.get_level_values('date').unique()[0]-pd.DateOffset(months=12),\n",
    "#                      end=data.index.get_level_values('date').unique()[-1])\n",
    "\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd3d84b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = df_final.index.get_level_values('date').unique()[0] - pd.DateOffset(months=12)\n",
    "end_date = df_final.index.get_level_values('date').unique()[-1]\n",
    "\n",
    "df_final = df_final.rename(index={0: \"Date\", 1: \"Ticker\"}, columns ={'adj close': 'Adj Close', 'volume': 'Volume'})\n",
    "\n",
    "# Slice the dataframe using pd.IndexSlice\n",
    "new_df = df_final.loc[pd.IndexSlice[start_date:end_date, stocks], :]\n",
    "new_df = new_df.unstack()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b906e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Calculate daily returns for each stock which could land up in our portfolio.\n",
    "\n",
    "* Then loop over each month start, select the stocks for the month and calculate their weights for the next month.\n",
    "\n",
    "* If the maximum sharpe ratio optimization fails for a given month, apply equally-weighted weights.\n",
    "\n",
    "* Calculated each day portfolio return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2bd2e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "returns_dataframe = np.log(new_df['Adj Close']).diff()\n",
    "returns_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167205a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fixed_dates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb562c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for start_date in fixed_dates.keys():\n",
    "    end_date = (pd.to_datetime(start_date)+pd.offsets.MonthEnd(0)).strftime('%Y-%m-%d')\n",
    "    cols = fixed_dates[start_date]\n",
    "    optimization_start_date = (pd.to_datetime(start_date)-pd.DateOffset(months=12)).strftime('%Y-%m-%d')\n",
    "    optimization_end_date = (pd.to_datetime(start_date)-pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "#     optimization_df = new_df[optimization_start_date:optimization_end_date]['Adj Close'][cols]\n",
    "     \n",
    "    print(start_date)\n",
    "    print(end_date)\n",
    "    print(cols)\n",
    "    print(optimization_start_date)\n",
    "    print(optimization_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816d298",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1120f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "portfolio_df = pd.DataFrame()\n",
    "\n",
    "for start_date in fixed_dates.keys():\n",
    "    \n",
    "    try:\n",
    "\n",
    "        end_date = (pd.to_datetime(start_date)+pd.offsets.MonthEnd(0)).strftime('%Y-%m-%d')\n",
    "\n",
    "        cols = fixed_dates[start_date]\n",
    "\n",
    "        optimization_start_date = (pd.to_datetime(start_date)-pd.DateOffset(months=12)).strftime('%Y-%m-%d')\n",
    "\n",
    "        optimization_end_date = (pd.to_datetime(start_date)-pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        optimization_df = new_df[optimization_start_date:optimization_end_date]['Adj Close'][cols]\n",
    "        \n",
    "        success = False\n",
    "        try:\n",
    "            weights = optimize_weights(prices=optimization_df,\n",
    "                                   lower_bound=round(1/(len(optimization_df.columns)*2),4))\n",
    "\n",
    "            weights = pd.DataFrame(weights, index=pd.Series(0))\n",
    "            \n",
    "            success = True\n",
    "        except:\n",
    "            print(f'Max Sharpe Optimization failed for {start_date}, Continuing with Equal-Weights')\n",
    "        \n",
    "        if success==False:\n",
    "            weights = pd.DataFrame([1/len(optimization_df.columns) for i in range(len(optimization_df.columns))],\n",
    "                                     index=optimization_df.columns.tolist(),\n",
    "                                     columns=pd.Series(0)).T\n",
    "        \n",
    "        temp_df = returns_dataframe[start_date:end_date]\n",
    "\n",
    "        temp_df = temp_df.stack().to_frame('return').reset_index(level=0)\\\n",
    "                   .merge(weights.stack().to_frame('weight').reset_index(level=0, drop=True),\n",
    "                          left_index=True,\n",
    "                          right_index=True)\\\n",
    "                   .reset_index().set_index(['date', 'ticker']).unstack().stack()\n",
    "\n",
    "        temp_df.index.names = ['date', 'ticker']\n",
    "\n",
    "        temp_df['weighted_return'] = temp_df['return']*temp_df['weight']\n",
    "\n",
    "        temp_df = temp_df.groupby(level=0)['weighted_return'].sum().to_frame('Strategy Return')\n",
    "\n",
    "        portfolio_df = pd.concat([portfolio_df, temp_df], axis=0)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "portfolio_df = portfolio_df.drop_duplicates()\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d93f0d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Visualize Portfolio returns and compare to SP500 returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1797da",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spy = yf.download(tickers='SPY',\n",
    "                  start='2015-01-01',\n",
    "                  end=dt.date.today())\n",
    "\n",
    "spy_ret = np.log(spy[['Adj Close']]).diff().dropna().rename({'Adj Close':'SPY Buy&Hold'}, axis=1)\n",
    "\n",
    "portfolio_df = portfolio_df.merge(spy_ret,\n",
    "                                  left_index=True,\n",
    "                                  right_index=True)\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a99a8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "portfolio_df = portfolio_df.merge(spy_ret,\n",
    "                                  left_index=True,\n",
    "                                  right_index=True)\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f30c5f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "portfolio_cumulative_return = np.exp(np.log1p(portfolio_df).cumsum())-1\n",
    "\n",
    "portfolio_cumulative_return[:'2023-09-29'].plot(figsize=(16,6))\n",
    "\n",
    "plt.title('Unsupervised Learning Trading Strategy Returns Over Time')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "\n",
    "plt.ylabel('Return')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcb121",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ceea61",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "stocks_df = pd.DataFrame(stocks, columns=['stock'])\n",
    "results_dir = os.path.join('..', 'results')\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "file_path = os.path.join(results_dir, 'ML_result.csv')\n",
    "\n",
    "stocks_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"saved to {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.792933,
   "end_time": "2024-09-15T18:03:59.418432",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/MLmodel.ipynb",
   "output_path": "executed_notebooks/MLmodel.ipynb",
   "parameters": {},
   "start_time": "2024-09-15T18:03:47.625499",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}